<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Correct NPOT mipmaps and parallel reduction</title>
  <style>
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <style>
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="style.css" />
  <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
    var mathElements = document.getElementsByClassName("math");
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") { katex.render(texText.data, mathElements[i], { displayMode: mathElements[i].classList.contains("display"), throwOnError: false } );
    }}});</script>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css" />
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Correct NPOT mipmaps and parallel reduction</h1>
<p class="date">05. June 2019</p>
</header>
<p>At some points, you have to dynamically generate mipmaps, i.e. downscale images. Either for textures, when they are not provided in the loaded image files or for render targets, e.g. to improve performance by running screen-space algorithms on downscaled render target versions or to find the average value of an image, e.g. like you have to for exposure eye-adaption based on the luminance of the rendered image.<br />
In most cases (textures, rough approximations) you don’t care too much about correctness. Even when you need the average value of an image, the result often doesn’t have to be 100% accurate. Still, naive mipmapping will produce results that might be quite off, at least for non-power-of-two (NPOT) render targets. Think of a 1920x1080 window, where usually non-power-of-two framebuffer attachments are used. This is nothing new though, it’s one of the reasons textures traditionally always had a power-of-two size, but we will quickly look at the issue nonetheless.</p>
<p>Let’s visualize it with a simple example: You have the image below, size 3x3.</p>
<figure>
<img src="assets/mip3x3.png" alt="3x3 pixel pattern" /><figcaption>3x3 pixel pattern</figcaption>
</figure>
<p>You now generate the first mipmap level for that image. That mipmap level has size 1x1 (mipmap sizes are rounded down by convention in OpenGL and Vulkan). In vulkan generating the mipmap is usually done via a blit (notice how we are already using a linear filter here for best results):</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode cpp"><code class="sourceCode cpp"><a class="sourceLine" id="cb1-1" title="1">vk::ImageBlit blit;</a>
<a class="sourceLine" id="cb1-2" title="2">blit.srcSubresource.layerCount = <span class="dv">1</span>;</a>
<a class="sourceLine" id="cb1-3" title="3">blit.srcSubresource.mipLevel = <span class="dv">0</span>;</a>
<a class="sourceLine" id="cb1-4" title="4">blit.srcSubresource.aspectMask = vk::ImageAspectBits::color;</a>
<a class="sourceLine" id="cb1-5" title="5"><span class="co">// srcOffset[1] is the size of the source</span></a>
<a class="sourceLine" id="cb1-6" title="6">blit.srcOffsets[<span class="dv">1</span>].x = <span class="dv">3</span>;</a>
<a class="sourceLine" id="cb1-7" title="7">blit.srcOffsets[<span class="dv">1</span>].y = <span class="dv">3</span>;</a>
<a class="sourceLine" id="cb1-8" title="8">blit.srcOffsets[<span class="dv">1</span>].z = <span class="dv">1</span><span class="bu">u</span>;</a>
<a class="sourceLine" id="cb1-9" title="9"></a>
<a class="sourceLine" id="cb1-10" title="10">blit.dstSubresource.layerCount = <span class="dv">1</span>;</a>
<a class="sourceLine" id="cb1-11" title="11">blit.dstSubresource.mipLevel = <span class="dv">1</span>;</a>
<a class="sourceLine" id="cb1-12" title="12">blit.dstSubresource.aspectMask = vk::ImageAspectBits::color;</a>
<a class="sourceLine" id="cb1-13" title="13"><span class="co">// dstOffets[1] is the size of the destination</span></a>
<a class="sourceLine" id="cb1-14" title="14">blit.dstOffsets[<span class="dv">1</span>].x = <span class="dv">1</span>;</a>
<a class="sourceLine" id="cb1-15" title="15">blit.dstOffsets[<span class="dv">1</span>].y = <span class="dv">1</span>;</a>
<a class="sourceLine" id="cb1-16" title="16">blit.dstOffsets[<span class="dv">1</span>].z = <span class="dv">1</span><span class="bu">u</span>;</a>
<a class="sourceLine" id="cb1-17" title="17"></a>
<a class="sourceLine" id="cb1-18" title="18">vk::cmdBlitImage(commandBuffer,</a>
<a class="sourceLine" id="cb1-19" title="19">    image, vk::ImageLayout::transferSrcOptimal, <span class="co">// mip 0: srcOptimal layout</span></a>
<a class="sourceLine" id="cb1-20" title="20">    image, vk::ImageLayout::transferDstOptimal, <span class="co">// mip 1: dstOptimal layout</span></a>
<a class="sourceLine" id="cb1-21" title="21">    {{blit}}, vk::Filter::linear);</a></code></pre></div>
<p>But then you get this:</p>
<figure>
<img src="assets/mip1x1.png" alt="Incorrect 1x1 mipmap" /><figcaption>Incorrect 1x1 mipmap</figcaption>
</figure>
<p>This is obviously not the mipmap we are looking for. The original image has quite some red pixels, why is the mipmap level only green? Well, the content for the pixel of the mipmap is determined via linearly filtering the source image. The destination pixel is perfectly in the center of the texture so to determine its contents, the center of the source image will be filtered. But since that is perfectly the center of the inner (center) pixel in the 3x3 image, no linear filtering will take place and the content of the mipmap is simply the center pixel of the original image. In other words: <strong>we discard 8/9 pixels and just copy one</strong>.</p>
<p>You may now think that the problem isn’t as bad when we start with a larger base image, but yes, it is. Because after some downsampling steps (in which we already discard quite some original pixels), we often enough end up with a 3x3 (or 2x3 or 3x2) mipmap which then, in turn, gets reduced to a 1x1 mipmap. So overall, a whole lot of pixels are discarded, even in the average case. So the value in the final 1x1 mipmap may be significantly different from the average value of the base image. It especially may only contain values from the center of the base image, discarding most of the rest.</p>
<p>Again, for conventional mipmaps (e.g. an albedo texture) this shouldn’t really be a huge problem since a rough approximation is usually enough, the mipmap levels don’t really have to contain the average. We can even improve it a bit by always using an even source size when blitting (i.e. intentionally discarding the last row for uneven sizes). In the example above, we would blit the 2x2 first pixels of the source image (discarding the last row/column) to the 1x1 mipmap, linear filtering works in that case and we only end up with <strong>5/9</strong> discarded pixels.</p>
<p>But what if we do this whole mip-mapping only to get the average of an image on the GPU? This is the case for simulated eye-adaption were we compute the average luminance (or, more correctly: average of <span class="math inline">log(luminance)</span>, i.e. we want the <a href="https://en.wikipedia.org/wiki/Geometric_mean">geometric mean</a>) of the rendered image to adjust the exposure of our HDR tone mapping. When you use the naive mipmap approximation it’s quite easy to notice that the adaption only takes a fraction of the screen into account. Additionally, the error will be highly dependent on the image size. That means when resizing the render target (i.e. the window), in one frame you might have an average luminance of 0.05 and in the next frame one of 0.2, although only one row of pixels was added/removed, i.e. the real geometric luminance mean has only changed insignificantly. Those properties are usually not acceptable.</p>
<p>So let’s do something fun: implement a compute shader that does what we want even faster than generating a mipmap. We aren’t after all interested in the mipmaps, this is more of a hack, to begin with. We just want the average value of a (possibly non-power-of-two) texture. <em>How hard can it be…?</em></p>
<h2 id="parallel-reduction">Parallel reduction</h2>
<p>Since the images will usually be too large to compute the average in a single pass and since we want to make good use of the parallel hardware we get on a GPU, we will use something that resembles mip-mapping except that we use a larger downscale factor (e.g. reducing the size by factor 8, 16 or 32 instead of just 2 in every pass). We will additionally downscale correctly, i.e. are not discarding any pixels.</p>
<ul>
<li>Create the image to compute the average for with a full mipmap chain</li>
<li>Starting with the original image (full size, mip 0) we run a compute shader in which every workgroup (of size <span class="math inline">(s, s)</span>) computes the average of a <span class="math inline">sxs</span> sized block in the source mip level and writes that to the destination mip level. To do so correctly we will round up the number of invocated workgroups as well as the size of the resulting mip level (instead of rounding down as it’s done for mipmap level sizes).</li>
<li>The compute shaders will simply implement what is known as <a href="https://en.wikipedia.org/wiki/Reduce_(parallel_pattern)">parallel reduction</a>, in this case, we just want to sum up all pixels in one block and then divide by the number of pixels in that block to get the average</li>
<li>Since the image size might not be a multiple of the block size, we have to care about border conditions: how do we compute the average value for blocks that don’t have the full pixel count to read?</li>
</ul>
<p>Requiring that the workgroup size is the same in x- and y-direction (i.e. blocks and workgroups are quadratic) simplifies the implementation a lot and there shouldn’t be a reason to choose something else. For the sake of simplicity and visualization, let’s fix the work group size (in each dimension) to <span class="math inline">s = 4</span> for the rest of the article. For a real implementation 8 or 16 tended to be a bit faster on my hardware. The border conditions are where this gets somewhat ugly. My first idea was to weigh the border pixels, i.e. always remember how much the last row/column is <em>worth</em> average-wise:</p>
<figure>
<img src="assets/mipWeigh.png" alt="Weighted reduction" /><figcaption>Weighted reduction</figcaption>
</figure>
<p>After this iteration, we would store <span class="math inline">(\frac{1}{4}, \frac{3}{4})</span> as the weight of the last pixel row/column. In the next iteration that weight would be applied to the values read from the last row/column. It would additionally used when diving by the number of pixels sampled, e.g. the last row/column wouldn’t be counted as one but as their weight. That algorithm worked, but in a second code iteration I went with a way that is somewhat easier to implement: for the sake of average calculation we just virtually pretend that the original image’s size is a power of our per-dimension work group size <span class="math inline">s</span> and we, therefore, have only full blocks in all reduction steps.</p>
<p>When calculating the average, sum up all pixels in the block and then always divide by the <span class="math inline">s * s</span> (i.e. the number of sampled pixels in a full block), even if block contained fewer pixels. You can imagine this as “summing up 0” for the pixels outside of the input image size. And then - at the end, when the average of the whole image was calculated like that - we will account for the 0-pixels in that average with a correction-factor that is simply calculated like <span class="math display">\frac{npo(width, s) * npo(height, s)}{width * height}</span> where <span class="math inline">npo(x, b)</span> is the smallest power of <span class="math inline">b</span> greater or equal to <span class="math inline">x</span>: <span class="math display">npo(x, b) = b^{\left\lceil\log_b x\right\rceil}</span> So the correction factor is the virtual number of pixels we sum up (including the zeroes) divided by the real number of pixels.</p>
<p>Although not exactly a formal proof (have yet to see one in a graphics post), you can see that this is correct like this: Take an average of a series of <span class="math inline">n</span> values <span class="math inline">v_i</span> <span class="math display">\frac{1}{n}\sum_{i=1}^{n}v_i</span> and now add <span class="math inline">k</span> zeroes to the series and again calculate the average: <span class="math display">\frac{1}{n + k}\sum_{i=1}^{n}v_i</span> (obviously the zeroes have no effect on the sum). If you now want the average without the artificial zeroes, you just have to multiply that with <span class="math inline">\frac{n + k}{n}</span>, which is exactly our correction factor above.</p>
<hr />
<p>With border conditions out of the way, the next question is which mip targets do we store to/read from? When <span class="math inline">s = 4</span> we reduce the image dimensions by factor 4 in each step so we could theoretically only use every other mip level. Except that mip level sizes are rounded down and we need rounding up (see the reduction sketch again, we also store not-full blocks). So in some cases, when the mip level size is too small, we have to use the previous mip level. In practice, this will probably only happen once since after that we got plenty of room in our mipmaps. Pseudo-codish it looks like this:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode cpp"><code class="sourceCode cpp"><a class="sourceLine" id="cb2-1" title="1">s = <span class="dv">4</span>; <span class="co">// our group size per dimension</span></a>
<a class="sourceLine" id="cb2-2" title="2">shift = log2(s); <span class="co">// mipmap jumping count</span></a>
<a class="sourceLine" id="cb2-3" title="3">src = <span class="dv">0</span>; <span class="co">// current source mip level</span></a>
<a class="sourceLine" id="cb2-4" title="4">dst = shift; <span class="co">// current destination mip level</span></a>
<a class="sourceLine" id="cb2-5" title="5">srcWidth = image.width;</a>
<a class="sourceLine" id="cb2-6" title="6">srcHeight = image.height;</a>
<a class="sourceLine" id="cb2-7" title="7"><span class="cf">while</span>(iwidth &gt; <span class="dv">1</span> || iheight &gt; <span class="dv">1</span>) {</a>
<a class="sourceLine" id="cb2-8" title="8">    <span class="co">// compute mip level size of level dst</span></a>
<a class="sourceLine" id="cb2-9" title="9">    mipWidth = <span class="bu">std::</span>max(image.width &gt;&gt; dst, <span class="dv">1</span><span class="bu">u</span>);</a>
<a class="sourceLine" id="cb2-10" title="10">    mipHeight = <span class="bu">std::</span>max(image.height &gt;&gt; dst, <span class="dv">1</span><span class="bu">u</span>);</a>
<a class="sourceLine" id="cb2-11" title="11"></a>
<a class="sourceLine" id="cb2-12" title="12">    <span class="co">// compute the needed size (rounding up!)</span></a>
<a class="sourceLine" id="cb2-13" title="13">    dstWidth = (srcWidth + s - <span class="dv">1</span>) / s;</a>
<a class="sourceLine" id="cb2-14" title="14">    dstcHeight = (srcHeight + s - <span class="dv">1</span>) / s;</a>
<a class="sourceLine" id="cb2-15" title="15"></a>
<a class="sourceLine" id="cb2-16" title="16">    <span class="co">// check if we have to back one level</span></a>
<a class="sourceLine" id="cb2-17" title="17">    <span class="cf">if</span>(iwidth &gt; mipWidth || iheight &gt; mipHeight) {</a>
<a class="sourceLine" id="cb2-18" title="18">        --dst;</a>
<a class="sourceLine" id="cb2-19" title="19">    }</a>
<a class="sourceLine" id="cb2-20" title="20"></a>
<a class="sourceLine" id="cb2-21" title="21">    <span class="co">// run compute shader here</span></a>
<a class="sourceLine" id="cb2-22" title="22">    <span class="co">// it reads from mip level src</span></a>
<a class="sourceLine" id="cb2-23" title="23">    <span class="co">// writes to mip level dst</span></a>
<a class="sourceLine" id="cb2-24" title="24">    <span class="co">// (dstWidth, dstHeight, 1) invocations are needed</span></a>
<a class="sourceLine" id="cb2-25" title="25">    <span class="co">// we have to pass (srcWidth, srcHeight) to the shader</span></a>
<a class="sourceLine" id="cb2-26" title="26"></a>
<a class="sourceLine" id="cb2-27" title="27">    src = dst;</a>
<a class="sourceLine" id="cb2-28" title="28">    srcWidth = dstWidth;</a>
<a class="sourceLine" id="cb2-29" title="29">    srcHeight = dstHeight;</a>
<a class="sourceLine" id="cb2-30" title="30">}</a></code></pre></div>
<p>With all that ugly groundwork out of the way, let’s get to the beautiful part: the parallel reduction shader. It needs the following inputs:</p>
<ul>
<li>the image of mip level <code>src</code></li>
<li>the size of mip level src (for the border condition) and <code>textureSize</code> doesn’t work here since the <em>real</em> size of that mip level may be larger than the sub-image we have written to. We pass that as push constant (uniform buffer objects work too but that requires us to keep a separate ubo for <em>every</em> pass and since this value only changes every time the original image size changes - in which case we have to re-record command buffers anyways - a push constant is the best solution here). In the code above this is simply <code>(srcWidth, srcHeight)</code>.</li>
<li>the workgroup size - not strictly an input - is specified as specialization constant. Gives some flexibility and makes the testing of various group sizes easier</li>
</ul>
<p>And it writes to the <code>dst</code> mipmap level Every workgroup will reduce one <span class="math inline">s x s</span> block to size 1 - computing its average - and write that value to the <code>dst</code> mipmap level, the output pixel is the workgroup ID (<code>gl_WorkGroupID</code>). Let’s look at the shader. This is already the optimized version, with various ideas from nvidia’s <a href="http://developer.download.nvidia.com/compute/cuda/1_1/Website/projects/reduction/doc/reduction.pdf">presentation on optimizing parallel reduction</a> as well as own ideas we will discuss shortly already applied. There are probably still some optimization opportunities left though.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode glsl"><code class="sourceCode glsl"><a class="sourceLine" id="cb3-1" title="1"><span class="pp">#version 450</span></a>
<a class="sourceLine" id="cb3-2" title="2"></a>
<a class="sourceLine" id="cb3-3" title="3"><span class="co">// we assume that x and y wor group sizes are the same.</span></a>
<a class="sourceLine" id="cb3-4" title="4"><span class="co">// There is no reason why we should choose something else and it</span></a>
<a class="sourceLine" id="cb3-5" title="5"><span class="co">// simplifies the computation here tremendously</span></a>
<a class="sourceLine" id="cb3-6" title="6"><span class="kw">layout</span>(local_size_x_id = <span class="dv">0</span>, local_size_y_id = <span class="dv">0</span>) <span class="dt">in</span>;</a>
<a class="sourceLine" id="cb3-7" title="7"><span class="co">// The source mipmap level with a linear sampler</span></a>
<a class="sourceLine" id="cb3-8" title="8"><span class="kw">layout</span>(set = <span class="dv">0</span>, <span class="dt">binding</span> = <span class="dv">0</span>) <span class="kw">uniform</span> <span class="dt">sampler2D</span> inLum;</a>
<a class="sourceLine" id="cb3-9" title="9"><span class="co">// The destination mipmap level</span></a>
<a class="sourceLine" id="cb3-10" title="10"><span class="kw">layout</span>(set = <span class="dv">0</span>, <span class="dt">binding</span> = <span class="dv">1</span>, r16f) <span class="kw">uniform</span> <span class="dt">writeonly</span> image2D outLum;</a>
<a class="sourceLine" id="cb3-11" title="11"></a>
<a class="sourceLine" id="cb3-12" title="12"><span class="kw">layout</span>(push_constant) <span class="kw">uniform</span> PCR {</a>
<a class="sourceLine" id="cb3-13" title="13">    uvec2 inSize; <span class="co">// size of valid pixels in the source level</span></a>
<a class="sourceLine" id="cb3-14" title="14">} pcr;</a>
<a class="sourceLine" id="cb3-15" title="15"></a>
<a class="sourceLine" id="cb3-16" title="16"><span class="co">// constant for all invocations</span></a>
<a class="sourceLine" id="cb3-17" title="17"><span class="dt">const</span> uint size = <span class="bu">gl_WorkGroupSize</span>.<span class="fu">x</span>; <span class="co">// == gl_WorkGroupSize.y</span></a>
<a class="sourceLine" id="cb3-18" title="18"><span class="dt">vec2</span> pixelSize = <span class="fl">1.</span>f / <span class="bu">textureSize</span>(inLum, <span class="dv">0</span>);</a>
<a class="sourceLine" id="cb3-19" title="19"></a>
<a class="sourceLine" id="cb3-20" title="20"><span class="co">// contains the current summed-up luminance</span></a>
<a class="sourceLine" id="cb3-21" title="21"><span class="dt">shared</span> <span class="dt">float</span> lum[<span class="dv">2</span> * size][<span class="dv">2</span> * size];</a>
<a class="sourceLine" id="cb3-22" title="22"></a>
<a class="sourceLine" id="cb3-23" title="23"><span class="co">// Loads the from the given pixel but makes sure to never sample</span></a>
<a class="sourceLine" id="cb3-24" title="24"><span class="co">// out-of-bounds.</span></a>
<a class="sourceLine" id="cb3-25" title="25"><span class="dt">float</span> <span class="fu">load</span>(<span class="dt">vec2</span> pixel) {</a>
<a class="sourceLine" id="cb3-26" title="26">    <span class="co">// return 0 when outside of image.</span></a>
<a class="sourceLine" id="cb3-27" title="27">    <span class="co">// don&#39;t make a multiplication or something else out of this</span></a>
<a class="sourceLine" id="cb3-28" title="28">    <span class="co">// since we might sample values like inf or nan from the texture</span></a>
<a class="sourceLine" id="cb3-29" title="29">    <span class="co">// outside of inSize</span></a>
<a class="sourceLine" id="cb3-30" title="30">    <span class="kw">if</span>(<span class="bu">any</span>(<span class="bu">greaterThan</span>(pixel, <span class="dt">vec2</span>(pcr.<span class="fu">inSize</span>)))) {</a>
<a class="sourceLine" id="cb3-31" title="31">        <span class="kw">return</span> <span class="fl">0.</span>f;</a>
<a class="sourceLine" id="cb3-32" title="32">    }</a>
<a class="sourceLine" id="cb3-33" title="33"></a>
<a class="sourceLine" id="cb3-34" title="34">    <span class="co">// on the image edge we might have to sample two (or even just</span></a>
<a class="sourceLine" id="cb3-35" title="35">    <span class="co">// one in case of corner) instead of the normal 4 pixels.</span></a>
<a class="sourceLine" id="cb3-36" title="36">    <span class="co">// Weigh them accordingly and make</span></a>
<a class="sourceLine" id="cb3-37" title="37">    <span class="co">// sure we never sample outside of the valid region of</span></a>
<a class="sourceLine" id="cb3-38" title="38">    <span class="co">// input mip level (gvien via pcr.inSize)</span></a>
<a class="sourceLine" id="cb3-39" title="39">    <span class="dt">float</span> fac = <span class="fl">1.</span>f;</a>
<a class="sourceLine" id="cb3-40" title="40">    <span class="kw">if</span>(pixel.<span class="fu">x</span> &gt; pcr.<span class="fu">inSize</span>.<span class="fu">x</span> - <span class="fl">0.5</span>) {</a>
<a class="sourceLine" id="cb3-41" title="41">        fac *= <span class="fl">0.5</span>f;</a>
<a class="sourceLine" id="cb3-42" title="42">        pixel.<span class="fu">x</span> = pcr.<span class="fu">inSize</span>.<span class="fu">x</span> - <span class="fl">0.5</span>;</a>
<a class="sourceLine" id="cb3-43" title="43">    }</a>
<a class="sourceLine" id="cb3-44" title="44">    <span class="kw">if</span>(pixel.<span class="fu">y</span> &gt; pcr.<span class="fu">inSize</span>.<span class="fu">y</span> - <span class="fl">0.5</span>) {</a>
<a class="sourceLine" id="cb3-45" title="45">        fac *= <span class="fl">0.5</span>f;</a>
<a class="sourceLine" id="cb3-46" title="46">        pixel.<span class="fu">y</span> = pcr.<span class="fu">inSize</span>.<span class="fu">y</span> - <span class="fl">0.5</span>;</a>
<a class="sourceLine" id="cb3-47" title="47">    }</a>
<a class="sourceLine" id="cb3-48" title="48"></a>
<a class="sourceLine" id="cb3-49" title="49">    <span class="kw">return</span> fac * <span class="bu">texture</span>(inLum, pixel * pixelSize).<span class="fu">r</span>;</a>
<a class="sourceLine" id="cb3-50" title="50">}</a>
<a class="sourceLine" id="cb3-51" title="51"></a>
<a class="sourceLine" id="cb3-52" title="52"><span class="dt">void</span> <span class="fu">main</span>() {</a>
<a class="sourceLine" id="cb3-53" title="53">    <span class="co">// 1: compute base of pixels this invocation is responsible for</span></a>
<a class="sourceLine" id="cb3-54" title="54">    uvec2 l = <span class="bu">gl_LocalInvocationID</span>.<span class="fu">xy</span>;</a>
<a class="sourceLine" id="cb3-55" title="55">    <span class="dt">vec2</span> pixel = <span class="dv">4</span> * <span class="bu">gl_GlobalInvocationID</span>.<span class="fu">xy</span>; <span class="co">// top-left of sampled pixels</span></a>
<a class="sourceLine" id="cb3-56" title="56">    pixel += <span class="dv">1</span>;</a>
<a class="sourceLine" id="cb3-57" title="57"></a>
<a class="sourceLine" id="cb3-58" title="58">    <span class="co">// 2: load responsible pixels</span></a>
<a class="sourceLine" id="cb3-59" title="59">    lum[<span class="dv">2</span> * l.<span class="fu">x</span> + <span class="dv">0</span>][<span class="dv">2</span> * l.<span class="fu">y</span> + <span class="dv">0</span>] = <span class="fu">load</span>(pixel + <span class="dt">vec2</span>(<span class="dv">0</span>, <span class="dv">0</span>)); <span class="co">// A</span></a>
<a class="sourceLine" id="cb3-60" title="60">    lum[<span class="dv">2</span> * l.<span class="fu">x</span> + <span class="dv">1</span>][<span class="dv">2</span> * l.<span class="fu">y</span> + <span class="dv">0</span>] = <span class="fu">load</span>(pixel + <span class="dt">vec2</span>(<span class="dv">2</span>, <span class="dv">0</span>)); <span class="co">// B</span></a>
<a class="sourceLine" id="cb3-61" title="61">    lum[<span class="dv">2</span> * l.<span class="fu">x</span> + <span class="dv">0</span>][<span class="dv">2</span> * l.<span class="fu">y</span> + <span class="dv">1</span>] = <span class="fu">load</span>(pixel + <span class="dt">vec2</span>(<span class="dv">0</span>, <span class="dv">2</span>)); <span class="co">// C</span></a>
<a class="sourceLine" id="cb3-62" title="62">    lum[<span class="dv">2</span> * l.<span class="fu">x</span> + <span class="dv">1</span>][<span class="dv">2</span> * l.<span class="fu">y</span> + <span class="dv">1</span>] = <span class="fu">load</span>(pixel + <span class="dt">vec2</span>(<span class="dv">2</span>, <span class="dv">2</span>)); <span class="co">// D</span></a>
<a class="sourceLine" id="cb3-63" title="63"></a>
<a class="sourceLine" id="cb3-64" title="64">    <span class="co">// 3: reduction loop</span></a>
<a class="sourceLine" id="cb3-65" title="65">    <span class="kw">for</span>(uint isize = size; isize &gt; <span class="dv">0</span>; isize /= <span class="dv">2</span>) {</a>
<a class="sourceLine" id="cb3-66" title="66">        <span class="bu">barrier</span>();</a>
<a class="sourceLine" id="cb3-67" title="67"></a>
<a class="sourceLine" id="cb3-68" title="68">        <span class="co">// sum up in tiles</span></a>
<a class="sourceLine" id="cb3-69" title="69">        <span class="kw">if</span>(l.<span class="fu">x</span> &lt; isize &amp;&amp; l.<span class="fu">y</span> &lt; isize) {</a>
<a class="sourceLine" id="cb3-70" title="70">            lum[l.<span class="fu">x</span>][l.<span class="fu">y</span>] += lum[isize + l.<span class="fu">x</span>][l.<span class="fu">y</span>]; <span class="co">// a, b, c, d</span></a>
<a class="sourceLine" id="cb3-71" title="71">            lum[l.<span class="fu">x</span>][l.<span class="fu">y</span>] += lum[l.<span class="fu">x</span>][isize + l.<span class="fu">y</span>]; <span class="co">// e, f, g, h</span></a>
<a class="sourceLine" id="cb3-72" title="72">            lum[l.<span class="fu">x</span>][l.<span class="fu">y</span>] += lum[isize + l.<span class="fu">x</span>][isize + l.<span class="fu">y</span>]; <span class="co">// i, j, k, l</span></a>
<a class="sourceLine" id="cb3-73" title="73">        }</a>
<a class="sourceLine" id="cb3-74" title="74">    }</a>
<a class="sourceLine" id="cb3-75" title="75"></a>
<a class="sourceLine" id="cb3-76" title="76">    <span class="co">// 4: first invocation in group writes average back</span></a>
<a class="sourceLine" id="cb3-77" title="77">    <span class="kw">if</span>(l.<span class="fu">x</span> == <span class="dv">0</span> &amp;&amp; l.<span class="fu">y</span> == <span class="dv">0</span>) {</a>
<a class="sourceLine" id="cb3-78" title="78">        <span class="co">// divide by the pixel count of the full block</span></a>
<a class="sourceLine" id="cb3-79" title="79">        <span class="dt">float</span> avg = lum[<span class="dv">0</span>][<span class="dv">0</span>] / (<span class="dv">4</span> * size * size);</a>
<a class="sourceLine" id="cb3-80" title="80">        <span class="bu">imageStore</span>(outLum, <span class="dt">ivec2</span>(<span class="bu">gl_WorkGroupID</span>.<span class="fu">xy</span>), <span class="dt">vec4</span>(avg));</a>
<a class="sourceLine" id="cb3-81" title="81">    }</a>
<a class="sourceLine" id="cb3-82" title="82">}</a></code></pre></div>
<p>The basic structure is already documented in the code, just follow the numbered comments. The reduction loop always sums up 3 tiles onto the base tile. In the sketch below, multiple colors in one field mean that they have been summed up (the sketch is ignoring the optimizations discussed below regarding group size, it displays the first reduction iteration for a block of size 4 per dimension):</p>
<figure>
<img src="assets/mipTiles.png" alt="Reduction Tiles" /><figcaption>Reduction Tiles</figcaption>
</figure>
<p>Before each reduction iteration, a barrier is needed. With Vulkan semantics for glsl, no <code>memoryBarrierShared</code> is needed here since barrier automatically performs that. See the <a href="https://github.com/KhronosGroup/GLSL/blob/master/extensions/khr/GL_KHR_vulkan_glsl.txt">GL_KHR_vulkan_glsl</a> and the <a href="https://www.khronos.org/registry/spir-v/specs/1.0/SPIRV.html">spirv</a> specifications for more details. For OpenGL it might be needed, see <a href="https://stackoverflow.com/questions/39393560" class="uri">https://stackoverflow.com/questions/39393560</a>. Also note that there cannot be any early returns, since then barriers become undefined behavior.</p>
<h3 id="optimizations">Optimizations</h3>
<p>Let’s start with the two most important optimizations that make this implementation a bit different from the more theoretical, simplistic above:</p>
<ol type="1">
<li>the shared luminance data buffer <code>lum</code> is twice the size in every dimension (four times the size in total) and every invocation fills in 4 of those values.</li>
<li>the values read in load aren’t aligned on pixel centers in the usual case (no border). The pixel center is always at <span class="math inline">(i + 0.5, j + 0.5)</span>, but we usually sample from whole numbers. We use linear sampling to read 4 values at once, with every texture access. That makes the load function and it’s border conditions even more complicated though. The input <code>sampler2D</code> must also have a linear sampler for that to work. So In total, every invocation (not at the border) will read <span class="math inline">(2 * 2) * (2 * 2) = 16</span> values from the texture instead of just 1. This helps keeping the number of invocations down that would just sit idly during most of the reduction loop. During the first reduction iteration, all invocations will be active (that’s what optimization 1 is for, why our shared buffer has twice the size in every dimension). For non-border invocations the sampling works like this (load is basically just one texture access at the given coordinates):</li>
</ol>
<figure>
<img src="assets/mipSample.png" alt="Default pixel sampling" /><figcaption>Default pixel sampling</figcaption>
</figure>
<p>For invocations that have to sample pixels beyond the input image size, <code>load</code> will return 0, as described in the theory. For border samples, it might move the sampled position by 0.5 in each dimension to make sure the last row/column pixels are sampled but nothing beyond it. It then applies a factor that makes the function overall behave as if it just normally sampled the given position but everything beyond the input texture size is 0. E.g. for the bottom right corner of the input mip level, with <span class="math inline">width \% 4 = 3</span> and <span class="math inline">height \% 4 = 1</span> it might look like this (load for C, D will return 0):</p>
<figure>
<img src="assets/mipSampleCorner.png" alt="Corner/Border pixel sampling" /><figcaption>Corner/Border pixel sampling</figcaption>
</figure>
<p>Note that we could alternatively achieve this with clearing the used mip levels to black once and bind a sampler with clampToBorder addressing mode and a black border. This would simplify the shader a bit, we basically move the responsibility for clamping into the sampler, i.e. onto the GPU. The clear might hurt performance a bit but shouldn’t have a big impact so this is a viable alternative.</p>
<p>The <code>load</code> function is only that explicit for understanding and documentation reasons. With some glsl foo we can reduce it to this:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode glsl"><code class="sourceCode glsl"><a class="sourceLine" id="cb4-1" title="1"><span class="dt">float</span> <span class="fu">load</span>(<span class="dt">vec2</span> pixel) {</a>
<a class="sourceLine" id="cb4-2" title="2">    <span class="dt">vec2</span> dist = <span class="bu">clamp</span>(pcr.<span class="fu">inSize</span> - (pixel - <span class="fl">0.5</span>), <span class="dv">0</span>, <span class="dv">1</span>);</a>
<a class="sourceLine" id="cb4-3" title="3">    <span class="dt">float</span> fac = dist.<span class="fu">x</span> * dist.<span class="fu">y</span>;</a>
<a class="sourceLine" id="cb4-4" title="4">    <span class="dt">vec2</span> uv = <span class="bu">min</span>(pixel, pcr.<span class="fu">inSize</span> - <span class="fl">0.5</span>) * pixelSize;</a>
<a class="sourceLine" id="cb4-5" title="5">    <span class="kw">return</span> fac * <span class="bu">texture</span>(inLum, uv).<span class="fu">r</span>;</a>
<a class="sourceLine" id="cb4-6" title="6">}</a></code></pre></div>
<p>Note how we still never sample from a location outside of pcr.inSize (not even via linear sampling) since that might introduce nan to the system - in which case the whole average computation would get nan’ed.</p>
<p>But now that every invocation reads from 16 pixels we have to adapt our algorithm for selecting matching mip levels accordingly. This is rather trivial though, instead of using <span class="math inline">s</span> as block width and height, we simply use <span class="math inline">4 * s</span>. That has an effect of <code>shift</code> in the pseudo code above as well as the previously discussed correction factor (we now need the next power of the block size, i.e. <span class="math inline">4 * s</span>).</p>
<p>The result looks like this (starting with full HD, <span class="math inline">s = 8</span>):</p>
<figure>
<img src="assets/mipExample0.png" alt="The original log(luminance) image, 1920x1080" /><figcaption>The original log(luminance) image, 1920x1080</figcaption>
</figure>
<figure>
<img src="assets/mipExample1.png" alt="First downscale pass, mip level 4, 60x32 used" /><figcaption>First downscale pass, mip level 4, 60x32 used</figcaption>
</figure>
<figure>
<img src="assets/mipExample2.png" alt="Second downscale pass, mip level 9, 2x2 used" /><figcaption>Second downscale pass, mip level 9, 2x2 used</figcaption>
</figure>
<figure>
<img src="assets/mipExample3.png" alt="The final downscaled version, mip level 10, 1x1" /><figcaption>The final downscaled version, mip level 10, 1x1</figcaption>
</figure>
<p>In each level, we reduced the mipmap size by <span class="math inline">4 * s = 32</span> in each dimension, but in comparison to standard mipmap sizes we round up (i.e. <span class="math inline">60 / 32 \to 2</span>). You may notice that e.g. the bottom pixels of the 2x2 level or the pixel of the final level aren’t really the average when compared to the corresponding blocks in the previous level. But this is due to our “sample 0 beyond the input image” approach. The border pixels may have values that are nearer 0 due to that (the black pixels here are negative, remember that we are dealing with <span class="math inline">log(luminance)</span>, so the pixels nearer 0 are brighter in this case). But this is fixed with the correction factor at the end! In this case, it’s</p>
<p><span class="math display">\frac{npo(1920, 32) * npo(1080, 32)}{1920 * 1080} \approx 517 </span></p>
<p>The value of the final mip level is <span class="math inline">\approx -0.01</span> so we get <span class="math inline">\approx -5.17</span> as average <span class="math inline">log(luminance)</span> value, i.e. <span class="math inline">0.02</span> as geometric mean of the luminance, which is correct (as this value is in linear space, i.e. not yet gamma corrected and the original image was indeed quite gloomy). You can see here already that forgetting to apply the correction factor will result in <strong>completely wrong</strong> results.</p>
<p>Also note that the unused regions of the mip levels can be left uninitialized, as we never access them. In this case, it’s pure coincidence that the GPU memory seems to contain a uniform value, I’ve also seen (and debugged…) cases where the memory contained values that equaled float NaN’s or infinities that completely messed up the calculation. The current code is careful to never sample them in any way.</p>
<h3 id="notes-on-further-optimization-ideas">Notes on further optimization ideas:</h3>
<p>Most of those ideas should be properly benchmarked, most will probably only result in an insignificant change or even in a worse result.</p>
<ul>
<li>we could load even more samples per invocation</li>
<li>choose a constant per-dimension workgroup size (<span class="math inline">s</span>) and do manual loop unrolling (as suggested by the nvidia presentation linked above)</li>
<li>benchmark if the sampling alternative using cleared mip levels and a clamped black border sampler is faster than the manual clamping at the border in <code>load</code></li>
<li>we could trade one addition in the reduction loop for a barrier e.g. by first adding up horizontally, then vertically (with a barrier in between) instead of adding up the three tiles. Not sure if that’s worth it though</li>
<li>see <a href="http://diaryofagraphicsprogrammer.blogspot.com/2014/03/compute-shader-optimizations-for-amd.html">this post</a> on efficient reduction compute shaders, using the nvidia presentation, this time specifically for AMD</li>
</ul>
<hr />
<p>For Vulkan, don’t forget to insert image memory barriers between the passes, you probably also want to transition the old destination (new source) mip level from general to shaderReadOnlyOptimal layout there. After all passes were executed and the last one wrote the final average to the last mipmap level, it can be copied from that to a buffer (or otherwise processed). But don’t forget the correction factor!</p>
<h2 id="alternative">Alternative</h2>
<p>We could also just use a power-of-two render target (just round up the window size to the next power-of-two) and then use the old mipmapping algorithm. But rendering that in its full size might not always be possible or require additional workarounds (e.g. in Vulkan all framebuffer attachments must have the same size). Additionally, when simply rendering a fraction of it, adaptions like the correction factor above are needed as well after mipmapping. You furthermore need a clear to black at the beginning which might not have been needed otherwise (depending on when you generate the luminance rendertarget). So, given that the compute shader alternative should be faster in pretty much all cases, uses less memory and doesn’t require any hacks, it should probably be preferred. The only reason I could think of not using compute shaders here is if your luminance format isn’t supported for storage images (but e.g. the r16f format is guaranteed to be supported by Vulkan).</p>
</body>
</html>
